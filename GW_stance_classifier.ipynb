{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a581b0-c068-41fb-867e-10011c69e06d",
   "metadata": {},
   "source": [
    "# INLP Group Work HS2025\n",
    "\n",
    "This document describes the group work aspect of the INLP module. We provide descriptions and code samples of the planned tasks.\n",
    "\n",
    "Please fill in details where explicitly indicated and leave everything else intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffa6d2-5a7d-4895-a8cb-30096eb93936",
   "metadata": {},
   "source": [
    "Group ID: 07\n",
    "\n",
    "Group members: Nico Roher, Alan Keller, Yven Weber, Yannick Lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53fa5b-d344-48f1-b80d-219802844516",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task\n",
    "\n",
    "| Name            | Split (Train/Test/Validation) |       Type |\n",
    "|-----------------|:-----------------------------:|-----------:|\n",
    "| emotion         | 3257/1421/374                 | Quaternary |\n",
    "| hate            | 9000/2970/1000                |     Binary |\n",
    "| irony           | 2862/784/955                  |     Binary |\n",
    "| offensive       | 11916/860/1324                |     Binary |\n",
    "| sentiment       | 45615/12284/2000              |    Ternary |\n",
    "| stance_abortion | 587/280/66                    |    Ternary |\n",
    "| stance_atheism  | 461/220/52                    |    Ternary |\n",
    "| stance_climate  | 355/169/40                    |    Ternary |\n",
    "| stance_feminism | 597/285/67                    |    Ternary |\n",
    "| stance_hillary  | 620/295/69                    |    Ternary |\n",
    "\n",
    "Following the same approaches presented in the module, solve the current tasks:\n",
    "\n",
    "1. Envision an NLP application using one or more of the data sets described in the table above\n",
    "2. Implement your solution in a Jupyter Notebook\n",
    "3. Document it using the provided Canvas document (that will guide you in the required aspects)\n",
    "4. Present your solution in the final lecture of the module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278d13f-0c2a-4d9d-b548-760f70e96456",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21e012c-6461-41f5-b750-4537751455d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (2.3.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alanr\\.platformio\\penv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install/upgrade core libs into this kernel\n",
    "%pip install -q -U \"transformers>=4.46.3\" \"huggingface_hub>=0.25.2\" \"datasets>=2.19\" \"scikit-learn>=1.3\" \"torch>=2.2\"\n",
    "\n",
    "# Verify versions and interpreter path\n",
    "import sys\n",
    "import transformers, huggingface_hub, datasets, sklearn, torch\n",
    "print(\n",
    "    \"transformers:\", transformers.__version__,\n",
    "    \"\\nhuggingface_hub:\", huggingface_hub.__version__,\n",
    "    \"\\ndatasets:\", datasets.__version__,\n",
    "    \"\\nsklearn:\", sklearn.__version__,\n",
    "    \"\\ntorch:\", torch.__version__,\n",
    "    \"\\npython:\", sys.version.split()[0],\n",
    "    \"\\nexec:\", sys.executable,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e563a0-da59-450e-8565-fec2bd7330d4",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "This section provides starter code for loading all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0988825e-72d0-4113-a903-a98b79ca99c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "# NOTE: this block loads all the available data into a dictionary\n",
    "# use the keys of the dictionary to access the required data set\n",
    "all_data = {}\n",
    "names = [\"emotion\", \"hate\", \"irony\",\n",
    "         \"offensive\", \"sentiment\", \"stance_abortion\",\n",
    "         \"stance_atheism\", \"stance_climate\", \"stance_feminist\",\n",
    "         \"stance_hillary\"]\n",
    "for name in names:\n",
    "    all_data[name] = datasets.load_dataset(\"tweet_eval\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9efeddd1-1f23-4945-afcd-cf94673a4177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['emotion', 'hate', 'irony', 'offensive', 'sentiment', 'stance_abortion', 'stance_atheism', 'stance_climate', 'stance_feminist', 'stance_hillary'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e484273b-0a37-44db-9bc2-4402b4ef5f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print description of the \"offensive\" data set\n",
    "print(all_data[\"offensive\"][\"train\"].info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93b5998-119e-48bc-80b7-8d0bbceb9f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non-offensive', 'offensive']\n"
     ]
    }
   ],
   "source": [
    "# print labels available for \"offensive\" data set (with order)\n",
    "print(all_data[\"offensive\"][\"train\"].info.features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba936a2-dbb9-4720-abb6-c2c2d28758ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '@user Bono... who cares. Soon people will understand that they gain nothing from following a phony celebrity. Become a Leader of your people instead or help and support your fellow countrymen.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of a non-offensive tweet\n",
    "all_data[\"offensive\"][\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee3bae6-0adc-497b-9463-15dd6c492dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '@user Eight years the republicans denied obamaâ€™s picks. Breitbarters outrage is as phony as their fake president.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of an offensive tweet\n",
    "all_data[\"offensive\"][\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda9ee8-15b4-4180-81d0-a9f729b31820",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "This section describes next steps in your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ccb7b4-8906-439f-9f72-477506d0d621",
   "metadata": {},
   "source": [
    "\n",
    "### Feature extraction/transformation and tokenization\n",
    "\n",
    "**Fill in** your NLP pipeline in the next blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defda669-7afd-401f-acbd-88d2528dfe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['none', 'against', 'favor'] - Train: 355 Val: 40 Test: 169\n"
     ]
    }
   ],
   "source": [
    "# Select stance dataset\n",
    "try:\n",
    "    ds = all_data[\"stance_climate\"]\n",
    "except Exception:\n",
    "    from datasets import load_dataset\n",
    "    ds = load_dataset(\"tweet_eval\", \"stance_climate\")\n",
    "\n",
    "label_names = ds[\"train\"].features[\"label\"].names\n",
    "X_train = ds[\"train\"][\"text\"]\n",
    "y_train = ds[\"train\"][\"label\"]\n",
    "X_val = ds[\"validation\"][\"text\"]\n",
    "y_val = ds[\"validation\"][\"label\"]\n",
    "X_test = ds[\"test\"][\"text\"]\n",
    "y_test = ds[\"test\"][\"label\"]\n",
    "\n",
    "print(\"Labels:\", label_names, \"- Train:\", len(X_train), \"Val:\", len(X_val), \"Test:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692093e-cdf0-458b-9087-93a5e746968e",
   "metadata": {},
   "source": [
    "### Vocabulary and vector representation\n",
    "\n",
    "**Fill in** the code for providing the vector representation of your data set(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c06a947-cd73-4b68-87ce-9b8bba4406d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312ce2f-6625-4553-afc6-4fe2185ed387",
   "metadata": {},
   "source": [
    "### Evaluation (traditional ML)\n",
    "\n",
    "**Fill in** the code for evaluating your NLP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ff1ea3-640b-4b03-8710-1b5c2b076cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2cf20-73c9-4045-9283-d3e64bbf408d",
   "metadata": {},
   "source": [
    "### Evaluation (neural network)\n",
    "\n",
    "**Fill in** the code for evaluating/comparing with a neural network (transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce02113-f3a3-4909-81c6-ba59ee68db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbb31d-50f4-4ad0-af8f-1857ef1121af",
   "metadata": {},
   "source": [
    "## That's all folks :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
